{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "weights = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_set():\n",
    "    def read_data(data_path):\n",
    "        base_x_train=[]\n",
    "        base_y_train=[]\n",
    "        label_folder = []\n",
    "        total_size = 0\n",
    "        for root, dirts, files in os.walk(data_path):\n",
    "            for dirt in dirts:\n",
    "                label_folder.append(dirt)\n",
    "            total_size += len(files)\n",
    "        for i in range(len(label_folder)):\n",
    "            print(label_folder[i])\n",
    "            labelPath = data_path+r'\\\\'+label_folder[i]\n",
    "            FileName = [f for f in listdir(labelPath) if isfile(join(labelPath, f))]\n",
    "            for j in range(len(FileName)):\n",
    "                path = labelPath+r'\\\\'+FileName[j]\n",
    "                img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.normalize(img,0,1,norm_type=cv2.NORM_MINMAX)\n",
    "                base_x_train.append(np.array(img).reshape(28*28,1).astype(np.float16))\n",
    "                base_y_train.append(label_folder[i])\n",
    "        print(np.array(base_x_train).shape)\n",
    "        indexs = np.random.choice(total_size,total_size, replace=False)\n",
    "        print(indexs)\n",
    "        return base_x_train, base_y_train, indexs, total_size\n",
    "\n",
    "    def read_testdata(data_path):\n",
    "        FileName = []\n",
    "        total_size = 0\n",
    "        base_x_test=[]\n",
    "        for root, dirts, files in os.walk(data_path):\n",
    "            for file in files:\n",
    "                FileName.append(file)\n",
    "            total_size += len(files)\n",
    "        for filename in FileName:\n",
    "            imgPath = data_path +r'\\\\'+ filename\n",
    "            img = cv2.imread(imgPath, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.normalize(img,0,1,norm_type=cv2.NORM_MINMAX)\n",
    "            base_x_test.append(np.array(img).reshape(28*28,1).astype(np.float16))\n",
    "        return FileName, base_x_test\n",
    "\n",
    "    def write_data(data_path,FileName,y_pred):\n",
    "        for index,filename in enumerate(FileName):\n",
    "            path = data_path +r'\\\\711083115.txt'\n",
    "            txt_name = filename.split('.')[0]\n",
    "\n",
    "            with open(path,'a') as f:\n",
    "                f.write(txt_name + \" \" + str(y_pred[index])+\"\\n\")\n",
    "    def test_accuracy():\n",
    "        data_path = r\"D:\\Code\\py\\NerualNetwork\\data\\Train data\"\n",
    "        f1 = r\"test_Ans.txt\"\n",
    "        f2 = r\"711083115.txt\"\n",
    "        ans = {}\n",
    "        pre = {}\n",
    "        total_size = 0\n",
    "        acc = 0\n",
    "        err = 0\n",
    "        with open(data_path+\"\\\\\"+f2) as p:\n",
    "            for line in p.readlines():\n",
    "                t = line.split(\" \")\n",
    "                pre[t[0]] = t[1]\n",
    "\n",
    "        with open(data_path+r\"\\\\\"+f1) as a:\n",
    "            for line in a.readlines():\n",
    "                total_size+=1\n",
    "                t = line.split(\" \")\n",
    "                ans[t[0]] = t[1]\n",
    "\n",
    "        for key, values in ans.items():\n",
    "            if pre[key] == values:\n",
    "                acc += 1\n",
    "            else:\n",
    "                err += 1\n",
    "        print(\"acc: \", (acc/total_size)*100)\n",
    "        print(\"err: \", (err/total_size)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### activate function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class activate_function():\n",
    "    def sigmoid (x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def threshold(x):\n",
    "        if x >= 0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network():\n",
    "    def createHidden(layer,inputsize, outputsize):\n",
    "        num = round(np.sqrt(6/(inputsize+outputsize)),5)\n",
    "        weights[layer] = np.asmatrix(np.random.uniform(-num,num,outputsize*inputsize).reshape(outputsize, inputsize))\n",
    "\n",
    "\n",
    "    def deltaW (output, Error):\n",
    "        one = np.asmatrix(np.ones(output.size)).T   \n",
    "        deltaset = np.multiply(np.multiply(output, (one-output)),Error).astype('float16')\n",
    "        return deltaset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from network import *\n",
    "import time\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "delta_w = {}\n",
    "\n",
    "def train(x,y,learningrate):\n",
    "    layerOutput = {}\n",
    "\n",
    "    for layer, w in weights.items():\n",
    "        if layer == \"I_h1\":\n",
    "            tmp = x.copy()\n",
    "        layerOutput[layer] = activate_function.sigmoid(np.dot(w,tmp)).astype(np.float16)\n",
    "        tmp = layerOutput[layer]\n",
    "        if layer == \"h1_O\":\n",
    "            predict = tmp\n",
    "    delta = {}\n",
    "    # bp\n",
    "    if np.all(predict != y):\n",
    "        # delta\n",
    "        for layer, value in reversed(layerOutput.items()):\n",
    "            if layer == \"h1_O\":\n",
    "                delta[layer] = network.deltaW(predict, y- predict)\n",
    "            else:\n",
    "                delta[layer] = network.deltaW(value, weights[prelayer].T*delta[prelayer])\n",
    "            prelayer = layer\n",
    "        #learning*del*input = delta_w\n",
    "        for layer, value in weights.items():\n",
    "            if layer == \"I_h1\":\n",
    "                input = x.T\n",
    "            else:\n",
    "                input = layerOutput[prelayer].T\n",
    "            try:\n",
    "                delta_w[layer] = np.sum([delta_w[layer],learningrate*delta[layer]*input], axis=0)\n",
    "            except:\n",
    "                delta_w[layer] = learningrate*delta[layer]*input\n",
    "            prelayer = layer\n",
    "\n",
    "# 4861/5000 97.22 accuracy\n",
    "def evaluate(indexs,x_train,y_train):\n",
    "    accuracy = 0\n",
    "    # error = 0\n",
    "    for index in indexs:\n",
    "        x = x_train[index]\n",
    "        num = int(y_train[index])\n",
    "        # y = np.asmatrix([0,0,0,0,0,0,0,0,0,0]).reshape(10,1)\n",
    "        # y[num] = 1\n",
    "        layerOutput = {}\n",
    "        for layer, w in weights.items():\n",
    "            if layer == \"I_h1\":\n",
    "                tmp = x.copy()\n",
    "            layerOutput[layer] = activate_function.sigmoid(np.dot(w,tmp)).astype(np.float16)\n",
    "            tmp = layerOutput[layer]\n",
    "            if layer == \"h1_O\":\n",
    "                predict = tmp\n",
    "                # t = y-predict\n",
    "                # error += 0.5*np.sum(np.multiply(t,t))\n",
    "        if np.argmax(predict) == num:\n",
    "            accuracy += 1\n",
    "    print(accuracy)\n",
    "    return accuracy/len(indexs)\n",
    "\n",
    "def test(x_test):\n",
    "    y_pred = []\n",
    "    for img in x_test:\n",
    "        layerOutput = {}\n",
    "        for layer, w in weights.items():\n",
    "            if layer == \"I_h1\":\n",
    "                tmp = img.copy()\n",
    "            layerOutput[layer] = activate_function.sigmoid(np.dot(w,tmp)).astype(np.float16)\n",
    "            tmp = layerOutput[layer]\n",
    "            if layer == \"h1_O\":\n",
    "                predict = tmp.copy()\n",
    "        y_pred.append(np.argmax(predict))\n",
    "    return y_pred\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    data_path=r\"D:\\Code\\py\\NerualNetwork\\data\\Training data\"\n",
    "    x_train, y_train, indexs,total_size=Data_set.read_data(data_path)\n",
    "    print(total_size)\n",
    "\n",
    "    learningrate = 0.1\n",
    "    network.createHidden(layer=\"I_h1\",inputsize=784,outputsize=64)\n",
    "    network.createHidden(layer=\"h1_O\",inputsize=64,outputsize=10)\n",
    "    \n",
    "    for epoch in range(15):\n",
    "        k=0\n",
    "        st= time.time()\n",
    "        for index in indexs:\n",
    "            x = x_train[index]\n",
    "            y = np.asmatrix([0,0,0,0,0,0,0,0,0,0]).reshape(10,1)\n",
    "            num = int(y_train[index])\n",
    "            y[num] = 1\n",
    "            train(x,y,learningrate)\n",
    "\n",
    "            for layer, value in delta_w.items():\n",
    "                weights[layer] += value                       #debug 2天 +->-\n",
    "            delta_w={}\n",
    "        acc =evaluate(indexs, x_train, y_train)\n",
    "        e = time.time()\n",
    "        print(\"Iter: {index:>4d}, accuracy: {accuracys: .4f}, time: {time: .4f}\".format(index=epoch,accuracys=acc*100,time=e-st))\n",
    "    test_path = r\"D:\\Code\\py\\NerualNetwork\\data\\Testing data\"\n",
    "    fileName, x_test=Data_set.read_testdata(test_path)\n",
    "    y_pred = test(x_test)\n",
    "    result_path = r\"D:\\Code\\py\\NerualNetwork\\data\"\n",
    "    Data_set.write_data(result_path, fileName, y_pred)\n",
    "    # Data_set.test_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os import listdir \n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 25000 files.\n",
      "folder: ['0', '1', '2', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "#Data visiting – os.walk()\n",
    "\n",
    "label_folder = []\n",
    "total_size = 0\n",
    "data_path = r\"C:\\Users\\anita\\Desktop\\TA\\CIFAR10_Test Image\\Training_data\"\n",
    "\n",
    "#os.walk() generates the file names(dirpath, dirnames, filenames) \n",
    "#in a directory tree by walking the tree either top-down or bottom-up.\n",
    "for root, dirts, files in os.walk(data_path): \n",
    "    for dirt in dirts:\n",
    "        label_folder.append(dirt)\n",
    "    total_size += len(files)\n",
    "\n",
    "    \n",
    "print(\"found\",total_size,\"files.\")\n",
    "print(\"folder:\",label_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 32, 32, 3)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "#Load image\n",
    "\n",
    "base_x_train = []\n",
    "base_y_train = []\n",
    "\n",
    "for i in range(len(label_folder)):\n",
    "    labelPath = data_path+r'\\\\'+label_folder[i]\n",
    "    \n",
    "    #listdir() returns a list containing the names of the entries in the directory given by path.\n",
    "    #isfile() is used to check whether the specified path is an existing regular file or not.\n",
    "    FileName = [f for f in listdir(labelPath) if isfile(join(labelPath, f))]\n",
    "    \n",
    "    for j in range(len(FileName)):\n",
    "        path = labelPath+r'\\\\'+FileName[j]\n",
    "        \n",
    "        #use cv2.imread read image.\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        \n",
    "        base_x_train.append(img)\n",
    "        base_y_train.append(label_folder[i])\n",
    "\n",
    "\n",
    "print(np.array(base_x_train).shape)\n",
    "print(np.array(base_y_train).shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 32, 32, 3)\n",
      "(25000, 5)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#Convert a category vector to a binary (0 or 1) matrix-type representation\n",
    "\n",
    "base_y_train = to_categorical(base_y_train)\n",
    "\n",
    "\n",
    "print(np.array(base_x_train).shape)\n",
    "print(np.array(base_y_train).shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 32, 32, 3)\n",
      "(25000, 5)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#Convert a category vector to a binary (0 or 1) matrix-type representation\n",
    "\n",
    "base_y_train = to_categorical(base_y_train)\n",
    "\n",
    "\n",
    "print(np.array(base_x_train).shape)\n",
    "print(np.array(base_y_train).shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 32, 32, 3)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "#Load image\n",
    "\n",
    "base_x_train = []\n",
    "base_y_train = []\n",
    "\n",
    "for i in range(len(label_folder)):\n",
    "    labelPath = data_path+r'\\\\'+label_folder[i]\n",
    "    \n",
    "    #listdir() returns a list containing the names of the entries in the directory given by path.\n",
    "    #isfile() is used to check whether the specified path is an existing regular file or not.\n",
    "    FileName = [f for f in listdir(labelPath) if isfile(join(labelPath, f))]\n",
    "    \n",
    "    for j in range(len(FileName)):\n",
    "        path = labelPath+r'\\\\'+FileName[j]\n",
    "        \n",
    "        #use cv2.imread read image.\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        \n",
    "        base_x_train.append(img)\n",
    "        base_y_train.append(label_folder[i])\n",
    "\n",
    "\n",
    "print(np.array(base_x_train).shape)\n",
    "print(np.array(base_y_train).shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the Data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (23750, 32, 32, 3) (23750, 5)\n",
      "Validation data: (1250, 32, 32, 3) (1250, 5)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation sets\n",
    "train_num = 23750\n",
    "x_train, x_valid = np.array(base_x_train)[:train_num], np.array(base_x_train)[train_num:]\n",
    "y_train, y_valid = np.array(base_y_train)[:train_num], np.array(base_y_train)[train_num:]\n",
    "\n",
    "print(\"Training data:\", x_train.shape, y_train.shape)\n",
    "print(\"Validation data:\", x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 4\n",
      "Answer(one-hot): [0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = random.randint(0, x_train.shape[0])\n",
    "plt.imshow(x_train[idx])\n",
    "plt.show()\n",
    "\n",
    "print(\"Answer:\", np.argmax(y_train[idx]))\n",
    "print(\"Answer(one-hot):\", y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(8, (3, 3), padding=\"same\", activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(5, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 8)         224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 141,173\n",
      "Trainable params: 141,173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# You can show the detail for it:\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1188/1188 [==============================] - 9s 6ms/step - loss: 269.7774 - accuracy: 0.2118 - val_loss: 1.7562 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1188/1188 [==============================] - 7s 6ms/step - loss: 1.6045 - accuracy: 0.2168 - val_loss: 1.8375 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1188/1188 [==============================] - 6s 5ms/step - loss: 1.6032 - accuracy: 0.2111 - val_loss: 1.8389 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1188/1188 [==============================] - 6s 5ms/step - loss: 1.6035 - accuracy: 0.2121 - val_loss: 1.8540 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1188/1188 [==============================] - 6s 5ms/step - loss: 1.6030 - accuracy: 0.2095 - val_loss: 1.8408 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1188/1188 [==============================] - 6s 5ms/step - loss: 1.6037 - accuracy: 0.2084 - val_loss: 1.8469 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1188/1188 [==============================] - 6s 5ms/step - loss: 1.6043 - accuracy: 0.2098 - val_loss: 1.8506 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1188/1188 [==============================] - 6s 5ms/step - loss: 1.6039 - accuracy: 0.2124 - val_loss: 1.8450 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1188/1188 [==============================] - 6s 5ms/step - loss: 1.6042 - accuracy: 0.2128 - val_loss: 1.8543 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1188/1188 [==============================] - 7s 6ms/step - loss: 1.6037 - accuracy: 0.2070 - val_loss: 1.8492 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "batch_size = 20\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"sgd\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=epoch, \n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_valid, y_valid)\n",
    ")\n",
    "#Saving the trained weights\n",
    "model.save(\"my_model.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #need install \"canda install pandas\"\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "x_new = x_test[:3]\n",
    "y_predict = model.predict(x_new)\n",
    "print(\"Predict probabilities:\", y_predict.round(2))\n",
    "print(\"Predict answers:\", y_predict.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the classification accuracy and loss-value\n",
    "# for the training-set.\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "# Get it for the validation-set (we only use the test-set).\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Plot the accuracy and loss-values for the training-set.\n",
    "plt.plot(acc, linestyle='-', color='b', label='Training Acc.')\n",
    "plt.plot(loss, 'o', color='b', label='Training Loss')\n",
    "    \n",
    "# Plot it for the test-set.\n",
    "plt.plot(val_acc, linestyle='--', color='r', label='Val Acc.')\n",
    "plt.plot(val_loss, 'o', color='r', label='Val Loss')\n",
    "\n",
    "# Plot title and legend.\n",
    "plt.title('Training and Val Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Ensure the plot shows correctly.\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
